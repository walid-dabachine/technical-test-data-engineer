<!-- Inscrivez vos rÃ©ponses dans ce document -->

## âš™ Instructions d'installation du projet

1. S'assurer que Python est bien installÃ© sur la machine. Ce projet est compatible avec python `>=3.9, <=3.13`. Il a Ã©tÃ© testÃ© en Python 3.10

2. CrÃ©er un environement virtuel nommÃ© `venv` :
    ```shell
    python -m venv venv
    ```

3. Lancer l'environement virtuel :
    ```shell
    source venv/bin/activate
    ```

4. Installer `poetry` pour la gestion des dÃ©pendances du projet :
    ```shell
    pip install poetry && pip install --upgrade pip
    ```

5. Lancer l'installation du projet via `poetry` :
    ```shell
    poetry install
    ````

6. A ce stade, le projet est installÃ© et prÃªt Ã  Ãªtre lancÃ©. CommenÃ§ons par lancer la suite de tests via `pytest` pour s'assurer que tout fonctionne : 
    ```shell
    pytest -rA
    ```
    Un total de 5 tests unitaires doivent passer avec succÃ¨s.
    
    Par manque de temps je n'ai pas pu implÃ©menter tous les tests qui me semblaient nÃ©cessaire. J'ai quand mÃªme pris le temps d'en mettre en place au moins un pour montrer la marche Ã  suivre

## âš¡ Lancement de l'extraction des donnÃ©es

1. S'ouvrir un terminal en arriÃ¨re fond en s'assurant de bien Ãªtre Ã  la racine du projet `technical-test-data-engineer` et en activant l'environement virtuel, puis lancer le serveur API Moovitamix localement : 
    ```shell
    python -m uvicorn src.moovitamix_fastapi.main:app --reload
    ```

2. S'ouvrir Ã  prÃ©sent un nouveau terminal de travail, toujours Ã  la racine du projet `technical-test-data-engineer` et lancer la pipeline d'ingestion, dans un premier temps, sans le module d'orchestration : 
    ```shell
    python src/moovitamix_data_connector/main.py --scheduling no
    ```
    La pipeline va lancer 3 flux d'ingestions: `tracks`, `users` et `listen_history`. Une fois l'exÃ©cution terminÃ©e, les donnÃ©es seront sauvegardÃ©es dans le dossier `data/01_source`

3. Pour activer le module d'orchestration `prefect` : 

    - S'assurer que `prefect` est bien installÃ© en roulant la commande suivante :
        ```shell
        prefect version
        ```
    - Ouvrir un nouveau terminal en arriÃ¨re fond pour lancer le serveur localement :
        ```shell
        prefect server start
        ```
        L'adresse du dashboard local s'affiche, normalement `http://127.0.0.1:4200`
    - Ouvrir un nouveau terminal de travail pour lancer la pipeline d'ingestion avec le module d'orchestration
        ```shell
        python src/moovitamix_data_connector/main.py --scheduling yes
        ```
    - Se rendre sur le dashboard Ã  l'adresse affichÃ©e prÃ©cedemment pour suivre le lancement des runs Ã  chaque minute et leur Ã©tat (sous l'onglet `Deployments`).
    
        Pour l'instant le projet n'implÃ©mente pas de mÃ©thodologie de versioning, les donnÃ©es sont donc extraites et Ã©crasÃ©es Ã  chaque minute sous `src/01_source`.

## ðŸ“– Description des choix techniques du projet

Globalement, le projet se dÃ©coupe en 7 thÃ©matiques techniques :

1. Setup du projet
2. Connecteur API Moovitamix
3. ModÃ¨le de donnÃ©es
4. Orchestration

Nous allons en explorer les choix, remarques et prochaines Ã©tapes.

### 1. Setup du projet

- Toutes les composantes sont codÃ©es en Python pour faciliter la collaboration avec l'Ã©quipe Data Science qui travaille principalement avec ce language. L'utilisation du SQL notamment pour le module de transformation de donnÃ©es est Ã©galement une option valide Ã  explorer

- J'ai utilisÃ© `poetry` pour la gestion des dÃ©pendances du projet. Sa capacitÃ© Ã  rÃ©soudre les dÃ©pendances automatiquement, centraliser en un seul fichier les configurations de dÃ©v et de prod, centraliser les commandes de build ainsi qu'encapsuler la gestion des dÃ©pendances et de l'environement virtuel en font un outil trÃ¨s robuste en comparaison Ã  une utilisation manuelle de `pip`

- Le projet est dÃ©coupÃ© en 3 modules techniques sous `src` :
    1. `moovitamix_fastapi` : Module de crÃ©ation de l'API (fourni par MoovAI)
    2. `moovitamix_data_connector` : Connecteur de donnÃ©es visant Ã  extraire les donnÃ©es `source` de l'API Moovitamix
    3. `data_transformation` : Module responsable de la crÃ©ation des pipelines de transformation de donnÃ©es de la couche `source` Ã  la couche `mart`

### 2. Connecteur API Moovitamix

- Le connecteur se trouve dans `src/moovitamix_data_connector.py`

- J'ai fait le choix de le coder from scratch bien que d'autres options sur Ã©tagÃ¨re et beaucoup plus robustes existent afin d'Ã©viter de rÃ©inventer la roue :
    * CrÃ©er un connecteur `Airbyte`
    * CrÃ©er un connecteur `Kedro`
    
    Cela s'explique notamment par 2 raisons:
    
    1. un manque de temps pour rentrer dans la doc de ses solutions respectives qui offrent un template prÃªt Ã  l'usage pour crÃ©er des connecteurs personnalisÃ©es mais nÃ©cessite d'adhÃ©rer Ã  leur modÃ¨le de donnÃ©es pour en tirer profit
    
    2. Les connecteurs gÃ©nÃ©riques de type API HTTP de ces 2 solutions n'offrent pas la gestion de la pagination et/ou de gestion du retry en cas de dÃ©passement de la limite de l'API

- Le connecteur gÃ¨re la pagination de l'API

- Le connecteur gÃ¨re pour l'instant uniquement les erreurs de type 429 (rate limit error)

- Le connecteur implÃ©mente un mechanisme de validation de donnÃ©es Ã  l'aide de `Pydantic`. Qui implÃ©mente pour l'instant exclusivement la validation du typage. Une des petites limitations de Pydantic ici est le fait qu'il n'offre pas de solution DataFrame-like permettant d'Ã©valuer la validitÃ© des donnÃ©es au niveau du Dataframe Pandas lors du runtime. Une solution comme `pandera` pourrait Ãªtre une bonne alternative pour amÃ©liorer cela pour Ã©tendre, simplifier et robustifier le scope de la validation

- Prochaines Ã©tapes:
    * PrÃ©sentemment, le connecteur se rÃ©alise systÃ©matiquement une extraction de donnÃ©es en mode "full load". Cela n'est pas trÃ¨s performant ici car pour ce type de donnÃ©es on peut s'imaginer que la volumÃ©trie peut trÃ¨s vite grossir ce qui rendra une extraction de type incrÃ©mentale beaucoup plus performante du point de vue du cout et du temps. On devra donc rÃ©flÃ©chir Ã  l'avenir Ã  l'implÃ©mentation d'une telle feature
    * Explorer l'Ã©ventualitÃ© d'adhÃ©rer Ã  un framework offrant des connecteurs sur-Ã©tagÃ¨re beacoup plus robuste afin d'Ã©viter de rÃ©inventer la roue
    * Etendre la gestion des erreurs Ã  plus de code HTML pour le rendre plus robuste

### 3. ModÃ¨le de donnÃ©es

#### 3.1 Structuration du pipeline de transformation de donnÃ©es

J'ai tirÃ© mon modÃ¨le de donnÃ©es des best practices provenant des frameworks open source utilisÃ©s par la communautÃ©, notamment [dbt](https://docs.getdbt.com/best-practices/how-we-structure/1-guide-overview). La donnÃ©e passe par 3 couches de transformation:

1. Source: DonnÃ©e brute sans transformation
2. Staging: Couche oÃ¹ sont appliquÃ©es les transformations de base de notre modÃ¨le de donnÃ©es (ex: casting, cleaning, ...)
3. Mart: Couche oÃ¹ se trouve les modÃ¨les de donnÃ©es utilisÃ©s par le business, l'Ã©quipe Data Science. Ils dÃ©finissent l'unique source of truth qui permet d'alimenter l'ensemble des cas d'usage analytiques plus bas dans le pipeline (ex: on y dÃ©finit ce qu'est un utilisateur, ce qu'est un track, ...)

Par manque de temps, j'ai eu la possibilitÃ© d'explorer uniquement la couche source qui est la couche oÃ¹ les donnÃ©es extraites par le connecteur API atterissent. Si demain on dÃ©cide d'intÃ©grer une nouvelle source de donnÃ©es comme une base de donnÃ©es SQL, c'est dans cette couche qu'atterisseront aussi les tables de cette BD.

Pour cet exercice, il n'y a pas Ã©normÃ©ment de transformation Ã  appliquer sur les donnÃ©es, les modÃ¨les dÃ©veloppÃ©s dans ces diffÃ©rentes couches auraient Ã©tÃ© lÃ©gers. Si j'avais eu davantage de temps j'aurais utilisÃ© `Kedro` pour rÃ©aliser ces transformations. Sa solution de pipelining et de visualisation des jobs de transformation de donnÃ©es le rend trÃ¨s efficace.

#### 3.2 Structuration du modÃ¨le de donnÃ©es

Etant donnÃ©e la nature du problÃ¨me, j'ai optÃ© pour une modÃ©lisation en Ã©toile (star schema) avec les composantes suivantes:

* `tracks` : table de dimension
* `users` : tables de dimension
* `listen_history` : table de fait

plus d'info dans les [best bractices dbt](https://docs.getdbt.com/terms/dimensional-modeling)

### 4. Orchestration

- J'ai utilisÃ© `Prefect` car moins verbeux qu'une solution comme `Airflow`. Avec le peu de temps que j'ai, j'ai prÃ©fÃ©rÃ© optÃ© pour cette solution pour implÃ©menter rapidement une soltuion d'orchestration. L'inconvÃ©nient d'une solution comme `Prefect` est sa maturitÃ© relativement faible en comparaison Ã  `Airflow` qui est la solution la plus populaire dans l'Ã©cosystÃ¨me Python.

- Ma solution n'implÃ©mente pas pour l'instant de versioning, Ã  chaque run du job les donnÃ©es fraiches viendront Ã©craser les anciennes donnÃ©es. Si j'avais plus de temps j'aurais d'abord commencÃ© par analyser les diffÃ©rentes options Ã  ma disposition pour implÃ©menter ce versioning. Cela peut passer par diffÃ©rentes possibilitÃ©s comme:
    - un format de donnÃ©es qui gÃ¨re by design les versions (ex: delta lake qui est du parquet sous stÃ©roide)
    - une structure de fichier/dossier qui conserve la tracabilitÃ© (ex: un dossier par date, avec un dossier `latest` contenant en tout temps la version la plus Ã  jour des donnÃ©es)

### 5. Monitoring de la santÃ© du pipeline

#### 5.1 Le monitoring, Ã  quoi Ã§a sert ?

Le monitoring de la santÃ© du pipeline est un point important car il permet en tout temps de savoir si la pipeline de donnÃ©es fonctionne comme convenu. 
Cela couvre des questions comme :
    
* La pipeline s'est elle bien lancÃ©e ?
* Il y a t-il eu des erreurs/warnings ?
* Le temps d'exÃ©cution de ma pipeline a t-elle Ã©tÃ© plus long que d'habitude ?
* La qualitÃ© des donnÃ©es ingÃ©rÃ©es est-elle conforme Ã  l'attendu

Pour Ãªtre pleinement robuste, une pipeline de donnÃ©es doit Ãªtre Ã©quipÃ©e d'une couche de monitoring qui aidera Ã  apporter les rÃ©ponses Ã  ces questions.

#### 5.2 Comment y arriver ?

Avant de penser Ã  une solution de monitoring en particulier, il est important de s'assurer de la mise en place d'un ensemble de must-haves :

* Ã‰mission de logs et de mÃ©triques: Une pipeline qui gÃ©nÃ¨re un ensemble de logs et de mÃ©triques CLAIRS et PERTINENTS sur la santÃ© de l'Ã©xecution de la pipeline. Ceci doit Ãªtre fait de maniÃ¨re centralisÃ©e afin d'en faciliter le traitement Ã  postÃ©riori. Rien de pire que devoir rÃ©concilier diffÃ©rents flux de logs/mÃ©triques vivant Ã  diffÃ©rents endroits...

* Collecte et stockage: les logs, les mÃ©triques et l'historique des exÃ©cutions sont des informations qui doivent Ãªtre collectÃ©es et stocker de maniÃ¨re sÃ©curitaire par la solution de monitoring

* QualitÃ© de donnÃ©es: un ensemble de tests doivent Ãªtre mis en place pour s'assurer du niveau de qualitÃ© des donnÃ©es (schÃ©ma de donnÃ©es, complÃ©tude, exactitude, fraicheur, ...)

* ObservabilitÃ©: Une solution de dashboarding simple d'utilisation permettant de visualiser les logs, les mÃ©triques et l'historique des runs

* Infrastructure fiable: qu'elle soit hostÃ©e ou managÃ©e, la solution choisie doit garantir la disponibilitÃ©, l'accessibilitÃ©, la scalabilitÃ© et la sÃ©curitÃ© de la solution et des donnÃ©es. Cet outil est une tour de controle qui doit Ãªtre fiable en tout temps.

* Alerting: sur la base des mÃ©triques collectÃ©es, dÃ©finir des seuils qui permettront de dÃ©clencher des alertes automatisÃ©es

#### 5.3 Quelles mÃ©triques observer ?

Il y a Ã©normÃ©ment de mÃ©triques qui peuvent Ãªtre implÃ©mentÃ©es dÃ©pendemment de contexte et de l'infrastructure. Globalement je les dÃ©composerai en 3 catÃ©gories:

1. QualitÃ© de donnÃ©es
    * Nombre de tests de donnÃ©es en erreur/succÃ¨s
    * Taux de doublons
    * Taux de valeurs manquantes

2. Performance
    * QuantitÃ© de donnÃ©es ingÃ©rÃ©es
    * Temps d'exÃ©cution
    * Usage CPU
    * Usage MÃ©moire

3. Erreurs
    * Nombre/Taux d'erreurs (peut Ãªtre dÃ©composer par types d'erreur: validation de donnÃ©e, compute, ...)
    * Nombre de warnings

Sur la base de ces mÃ©triques nous pouvons dÃ©finir seuils qui vont dÃ©clencher des alertes automatisÃ©es. Ceci peut Ãªtre accompagnÃ© d'un systÃ¨me de reporting gÃ©nÃ©rant un rapport templatisÃ© et envoyÃ© Ã  la frÃ©quence de notre choix (ici quotidienne) via des canaux adaptÃ©s (courriel, slack, ...)

### 6 et 7. Automatisation du calcul des recommendations

Je vais rÃ©pondre dans cette section Ã  la fois Ã  la question 6 et 7.

Nous avons traitÃ© dans les parties prÃ©cÃ©dentes le volet donnÃ©es, nous allons Ã  prÃ©sent nous intÃ©resser Ã  la partie modÃ©lisation et architecture.

Avant de se lancer dans l'implÃ©mentation du systÃ¨me de recommandation, il convient d'abord de concevoir l'architecture du systÃ¨me au global. Nous parlons ici de systÃ¨me car le livrable final est une solution ML, plutÃ´t complexe, et composÃ©e de diffÃ©rentes composantes qui communiquent les unes avec les autres.

Revenons tout d'abors au besoin client. Nous voulons crÃ©er un systÃ¨me pour recommander Ã  nos utilisateurs des listes de lecture. Pour concevoir la solution, nous devons prendre en compte diffÃ©rents aspects qui n'ont pas nÃ©cessairement Ã©tÃ© Ã©voquÃ© par le client:

1. A quelle frÃ©quence vont Ãªtre servies les recommendations de listes de lecture ? Je vois au moins 2 scÃ©narios basiques :
    
    - 1.1. On met Ã  jour les recommendations d'un utilisatuer Ã  chaque nouvelle mise Ã  jour de son historique (ex: aprÃ¨s l'Ã©coute d'un nouveau titre). L'avantage est que l'utilisateur se voit constamment proposer de nouvelles recommendatins fraiches. L'inconvÃ©nient est que cela est trÃ¨s gourmand en ressource et nÃ©cessite des choix d'architecture plus complexes qui font notamment entrer en jeu des composantes streaming pour permettre une interrogation du modÃ¨le en temps rÃ©el.

    - 1.2. On met Ã  jour les recommendations d'un utilisateur Ã  une frÃ©quence rÃ©guliÃ¨re (ex: Ã  chaque 24h). L'avantage est que l'infÃ©rence se fait en mode batch, beaucoup moins gourmandes en ressources. L'inconvÃ©nient est que les recommendations ne sont pas les plus fraiches. A noter que dans ce cas de figure, les recommendations seront prÃ©-crunchÃ©es pour tous les utilisateurs de la base, ce qui peut Ãªtre trÃ¨s coÃ»teux. Il existe des stratÃ©gies pour diminuer le coÃ»t, par exemple, gÃ©nÃ©rer les recommendations que pour les clients actifs et/ou les tops clients.

2. Quelle est l'interface qui va Ãªtre responsable de servir les prÃ©dictions ? BD, API, fichiers plats (csv, parquet, ...) ? Afin de rÃ©pondre Ã  cette question, il faut notamment comprendre quels sont les systÃ¨mes downstream qui vont consommer les prÃ©dictions (web app, mobile, job, ...). En rÃ¨gle gÃ©nÃ©rale, lorsqu'il s'agit d'intÃ©grer un modÃ¨le de ML Ã  des systÃ¨mes complexes, le principal challenge est de le rendre intÃ©ropÃ©rable. Dans ce genre de cas de figure, l'utilisation d'API pour exposer un modÃ¨le sous forme de service tout en abstrayant sa complexitÃ©, est une solution de choix. Pour garantir la robustesse du systÃ¨me, les recommendations pourraient d'abord Ãªtre inscrits dans une BD une fois le batch d'infÃ©rence terminÃ© puis l'API serait chargÃ©e uniquement d'interroger la BD pour collecter les rÃ©sultats

3. Quelle est la frÃ©quence de rÃ©-entrainement du modÃ¨le ? On fait l'hypothÃ¨se ici que le modÃ¨le est rÃ©entrainÃ© de maniÃ¨re automatique que lorsque les performances du modÃ¨le chutent.

Si on prend un peu de hauteur, dÃ©cider sur ces composantes d'architecture, Ã§a revient finalement Ã  arbitrer entre 3 composantes: Ã  quelle frÃ©quence est servi le client, Ã  quelle vitesse et pour quel coÃ»t.

Parfait! Sur la base d'hypothÃ¨ses, qu'il faudrait dans un contexte rÃ©el vÃ©rifier bien sÃ»r avec le client, nous venons de dÃ©finir quelques concepts clÃ©s de notre solution. Voici Ã  prÃ©sent une liste des composantes possibles de ce systÃ¨me (tous ces composants ne sont pas indispensables):

1. Une pipeline de feature engineering (collecte, cleaning et enrichissement des donnÃ©es)
2. Une pipeline d'entraÃ®nement du modÃ¨le (comprenant Ã©galement l'Ã©valuation et la validation du modÃ¨le)
3. Une pipeline d'infÃ©rence
5. Model registry: en charge de conserver l'historique des modÃ¨les utilisÃ©s et de tagger le modÃ¨le de rÃ©fÃ©rence
6. Feature Store: magasin de features en charge de stocker les features et d'Ã©viter de les recalculer lorsqu'elles ont dÃ©jÃ  Ã©tÃ© calculÃ©es dans le passÃ© et sont disponibles
7. Service de serving (API): module en charge de servir les prÃ©dictions, via API, en lisant la BD populÃ©e par la pipeline d'infÃ©rence
8. Module de monitoring: ConnectÃ© au module de serving il est en charge de mesurer en temps rÃ©el la performance du modÃ¨le et de dÃ©tecter de potentiels chutes de performance (drift)
9. CI/CD: Pour automatiser l'intÃ©gration, le build et le dÃ©ploiement de la solution dans l'infrastructure cible
10. (Une derniÃ¨re composante que je mets un peu entre parenthÃ¨ses dÃ©pendemment du besoin de l'Ã©quipe DS et du niveau de maturitÃ© de ce qui est souhaitÃ©: une plateforme d'expÃ©rimentation permettant Ã  l'Ã©quipe d'itÃ©rer sur leurs modÃ¨les tout en gardant l'historique des itÃ©rations)

Voici un diagramme trÃ¨s simplifiÃ© dÃ©crivant ce processus avec quelques solutions sur le marchÃ© permettant de rÃ©pondre aux besoins :

![alt text](architecture_diagram.png)

Pour automatiser le rÃ©entrainement du modÃ¨le de recommendation nous avons besoin de 4 Ã©lÃ©ments:

1. Une couche de monitoring ayant accÃ¨s Ã  l'historique des prÃ©dictions
2. Une mÃ©trique permettant de mesurer la performance rÃ©elle du modÃ¨le en production. C'est peut Ãªtre une des Ã©tapes la plus complexe, Ã©tant donnÃ© qu'il est assez chalengeant de mesurer la performance d'une recommendation car n'il y a pas de ground truth. Quelques pistes:
    * mettre en place une feedback loop active avec les utilisateurs (ex: like, dislike, ...) permettant d'avoir un signal sur la validitÃ© de cette recommendation
    * mettre en place une feedback loop passive permettant de mesurer si la recommendation a fait son effet (ex: la musique a Ã©tÃ© Ã©coutÃ©e, pendant un certain temps long, ...)
    * mettre en place une feedback loop Ã  base de rÃ¨gle d'affaires qui permettent de qualifier la validitÃ© de la recommendation (ex: si la playlist est assez variÃ©e tout en gardant une cohÃ©rence avec le profil de l'utilisateur, alors c'est un succÃ¨s)
3. DÃ©finir des rÃ¨gles/seuils permettant de qualifier le type de drift pour lequel on veut dÃ©clencher un rÃ©entrainement
4. DÃ©finir la mÃ©canique de dÃ©clenchement et connecter la solution de monitoring Ã  notre solution d'orchestration